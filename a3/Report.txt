Report – Liam Jackson (1000691281) % Cam Chabma (1000344987)
For part 1, we were tasked with completed a raytracer to render out a given scene in two different views. Our first step to this was to write the intersection code. For this, we read up on the slides and used some tutorial notes from another professor’s lecture to aid us and help us understand how the intersection properly works. We got the square intersection nearly working perfectly on our first try, but the ellipse intersection gave us a lot of trouble. We simple copied over the code from our square intersection and replaced the parts that use the geometric shape of a square and tried to plug in an ellipse shape instead. This gave us mixed results. We eventually realized that intersection for an ellipse is done wildly different, so after reading up on it more online, we were able to implement it. We then moved onto the Phong shading. This was relatively simple, and really only required us to read over the slides and look up the ray documentation to retrieve the material properties needed to compute the colour. We then were able to retrieve this in our raytracer file to get some results. We seemed to get the shape of the ellipse and square, but both renders were from the same view, and it was noticeably darker than the example images in the handout. To solve our first problem by realizing we were performing the view to world transformation incorrectly and it had to be applied to both the rays origin and direction. This gave us two different renders from two different views, but it was still dark. After multiple hours of our own frustration, and talking with my professor, we realized we were doing the normalization of the intersection incorrectly. We were normalizing it before we applied the world to model transformation, when we should have been doing it after. After changing our code, we were getting good results on our images, and it looked very similar to the example image.
Now we needed to do anti-aliasing. This didn’t take us too long, for each pixel, we run 2 more for loops to separate each pixel into NxM sub-pixels and computed the ray’s colour for each subpixel then did the mean over them to compute our anti-aliased colour. The only minor issue we had here was simply dealing with logic errors in the for loops so we computed, summed, and averaged the colours correctly.
It’s worth noting, for part 1, we worked on each part together. Sidenote, for the renders, we purposely set the square to be orange in the scene signature just to make it easier to see.

For part 2, we decided we were going to make a game using openGL. We used one of our assignment 2s as a base for it. We decided we were going to make a tennis game. One of us began working on the court and ball movement, and the other modeled and animated the player. After we each completed our parts separately, we put our files together so we had a court, with two players on each end and a ball bouncing back and forth. We then set it up so keyboard strokes could move each player and swing with each player. Once we completed the controls segment, we got to work on having the player interact with the ball. We set it up so if the ball has reached either end of the court and is in the player’s width, and the player is currently swinging, reverse the velocity of the ball, otherwise start back in the middle and award the other player a point. This was the bare bones of the game, and from here we added additional minor features, like the lighting and net texture, and bouncing of the ball, scoring system and camera placement. Once again worth noting, aside from the modeling, we did each part together.
